{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows `Sparkify.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b89960ea908477e9dee9d7aa8806c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1548971932490_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-12-4.us-east-2.compute.internal:20888/proxy/application_1548971932490_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-1-205.us-east-2.compute.internal:8042/node/containerlogs/container_1548971932490_0003_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import avg, col, concat, count, desc, \\\n",
    "asc, explode, lit, min, max, split, stddev, udf, isnan, when, rank, \\\n",
    "log, sqrt, cbrt, exp, countDistinct, monotonically_increasing_id\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.functions import abs as Fabs\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, \\\n",
    "LogisticRegressionModel, RandomForestClassifier, \\\n",
    "RandomForestClassificationModel, GBTClassifier, \\\n",
    "GBTClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, \\\n",
    "PCA, RegexTokenizer, Tokenizer, StandardScaler, StopWordsRemover, \\\n",
    "StringIndexer, VectorAssembler, MaxAbsScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from time import time\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7256d5fd96234a419dce5fc56dddcb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pandas.plotting import scatter_matrix\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7e47e363cf4843874f612b9b3c6432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eca07fee3a4fd08c5aa056b3361fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')"
     ]
    }
   ],
   "source": [
    "# Read in full sparkify dataset\n",
    "event_data = \"s3n://dsnd-sparkify/sparkify_event_data.json\"\n",
    "df = spark.read.json(event_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac71ba0e8d1a46a69b39a39a9a121236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.dropna(how='any', subset=['userId', 'sessionId'])\n",
    "df = df.filter(df['userId'] != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672bf1f3d24943fc963cc981c227b233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 26259199.\n",
      "Column artist has 5408927 missing values.\n",
      "Column auth has 0 missing values.\n",
      "Column firstName has 778479 missing values.\n",
      "Column gender has 778479 missing values.\n",
      "Column itemInSession has 0 missing values.\n",
      "Column lastName has 778479 missing values.\n",
      "Column length has 5408927 missing values.\n",
      "Column level has 0 missing values.\n",
      "Column location has 778479 missing values.\n",
      "Column method has 0 missing values.\n",
      "Column page has 0 missing values.\n",
      "Column registration has 778479 missing values.\n",
      "Column sessionId has 0 missing values.\n",
      "Column song has 5408927 missing values.\n",
      "Column status has 0 missing values.\n",
      "Column ts has 0 missing values.\n",
      "Column userAgent has 778479 missing values.\n",
      "Column userId has 0 missing values."
     ]
    }
   ],
   "source": [
    "# # Examine the number of missing values in each column\n",
    "# print(\"Total number of rows in the dataset: {}.\".format(df.count()))\n",
    "\n",
    "# for coln in df.columns:\n",
    "#     missing_count = df.filter((isnan(df[coln])) | (df[coln].isNull()) | (df[coln] == \"\")).count()\n",
    "#     print(\"Column {} has {} missing values.\".format(coln, missing_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fcb693da5c426f9e6d5f4205705c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define churn\n",
    "flag_churn_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "churn = df.withColumn(\"churned\", flag_churn_event(\"page\"))\\\n",
    "    .select(['userId', 'churned'])\\\n",
    "    .groupBy('userId').agg(max('churned').alias(\"churn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a93a3677cc548b08d12b7ee56670d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22278"
     ]
    }
   ],
   "source": [
    "# churn.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d3c89cfb074f318ed32fe0a0c69ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Latest level\n",
    "func_levels = udf(lambda x: 1 if x==\"paid\" else 0, IntegerType())\n",
    "levels = df.select(['userId', 'level', 'ts'])\\\n",
    "    .orderBy(desc('ts'))\\\n",
    "    .dropDuplicates(['userId'])\\\n",
    "    .select(['userId', 'level'])\\\n",
    "    .withColumn('level', func_levels('level').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dccfafa35784d738165366d5208cdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time since registration in seconds, and gender\n",
    "func_gender = udf(lambda x: 1 if x==\"M\" else (0 if x==\"F\" else -1), IntegerType())\n",
    "time_gender = df.groupBy(['userId', 'gender'])\\\n",
    "    .agg(max('ts'), avg('registration'))\\\n",
    "    .withColumn('time_since_regi', (col('max(ts)')-col('avg(registration)'))/lit(1000))\\\n",
    "    .withColumn('gender', func_gender('gender'))\n",
    "\n",
    "avg_time = time_gender.select(avg('time_since_regi')).collect()[0]['avg(time_since_regi)']\n",
    "time_gender = time_gender.fillna(avg_time, subset=['time_since_regi'])\\\n",
    "    .drop('max(ts)').drop('avg(registration)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594807f0933b4dccb5acb837a6534261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Number of artists, total length, number of sessions, number of songs, and number of page events\n",
    "# # that the user has engaged\n",
    "# engagement = df.groupBy('userId')\\\n",
    "#     .agg(countDistinct('artist').alias('num_artists_dist'), \n",
    "#          countDistinct('sessionId').alias('num_sessions'),\n",
    "#          countDistinct('song').alias('num_songs_dist'),\n",
    "#          count('song').alias('num_songs'),\n",
    "#          count('page').alias('num_events'),\n",
    "#          Fsum('length').alias('tot_length')\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ede3387e794c28b3a9d82300bee4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Statistics of the number of songs per artist that the user has listened to\n",
    "# per_artist = df.filter(~df['artist'].isNull())\\\n",
    "#     .groupBy(['userId', 'artist'])\\\n",
    "#     .agg(count('song').alias('num_songs'))\\\n",
    "#     .groupBy('userId')\\\n",
    "#     .agg(avg(col('num_songs')).alias('avg_songs_per_artist'),\n",
    "#          stddev(col('num_songs')).alias('std_songs_per_artist')\n",
    "#         )\\\n",
    "#     .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b821401daab249d8bf47da0adf728542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Statistics of the time spent sper session (float)\n",
    "per_session = df.groupBy(['userId', 'sessionId'])\\\n",
    "    .agg(max('ts'), min('ts'), count('song').alias('num_songs'))\\\n",
    "    .withColumn('time', (col('max(ts)')-col('min(ts)'))/lit(1000))\\\n",
    "    .groupBy('userId')\\\n",
    "    .agg(stddev(col('time')), \n",
    "         avg(col('time')),\n",
    "         stddev(col('num_songs')).alias('std_songs_per_session'),\n",
    "         avg(col('num_songs')).alias('avg_songs_per_session')\n",
    "        )\\\n",
    "    .withColumnRenamed('stddev_samp(time)', 'std_time_per_session')\\\n",
    "    .withColumnRenamed('avg(time)', 'avg_time_per_session')\\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a5409c426f43b2a35dd851b36e717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for coln in ['avg_time_per_session', 'std_time_per_session']:\n",
    "#     missing_count = per_session.filter(\n",
    "#         (isnan(per_session[coln])) | (per_session[coln].isNull()) | (per_session[coln] == \"\")\n",
    "#     ).count()\n",
    "#     print(\"Column {} has {} missing values.\".format(coln, missing_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb18ad66dd0f4287a906d72c7e6e80d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate usage fraction of each userAgent\n",
    "window = Window.partitionBy(\"userId\").rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)\n",
    "func_agent_device = udf(\n",
    "    lambda x: \"user_agent_\"+x.split('(')[1].replace(\";\", \" \").split(\" \")[0] if '(' in str(x) else 'user_agent_none', \n",
    "    StringType()\n",
    ")\n",
    "\n",
    "df = df.fillna('', subset=['userAgent'])\n",
    "agents = df.withColumn(\"userAgent\", func_agent_device(col(\"userAgent\")))\n",
    "agents = agents.groupBy([\"userId\", 'userAgent'])\\\n",
    "    .agg(count(\"userAgent\").alias(\"user_agent_usage_count\"))\\\n",
    "    .withColumn('total', Fsum(col('user_agent_usage_count')).over(window))\\\n",
    "    .withColumn('user_agent_usage', col('user_agent_usage_count')/col('total'))\\\n",
    "    .groupBy(\"userId\").pivot(\"userAgent\").sum(\"user_agent_usage\")\\\n",
    "    .fillna(0)\\\n",
    "    .drop('user_agent_none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dc055ddd6649a0835befd7c822fd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count usages of each page event by each user\n",
    "pages_to_exclude = ['Cancel', 'Downgrade', 'Cancellation Confirmation', 'Upgrade', \n",
    "                    'Submit Registration', 'Login', 'Register']\n",
    "func_pages = udf(lambda x: \"page_\"+x.replace(\" \", \"_\").lower())\n",
    "pages = df.filter(~df['page'].isin(pages_to_exclude))\\\n",
    "    .withColumn(\"page\", func_pages(df[\"page\"]))\\\n",
    "    .groupBy(['userId']).pivot(\"page\").agg(count('page'))\\\n",
    "    .fillna(0)\n",
    "pages = pages.withColumn(\"page_up_down_ratio\", pages[\"page_thumbs_up\"]/(pages['page_thumbs_down']+0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492e990038540ee92fda0b8258fc51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the fraction of each page event by each user\n",
    "pages = pages.withColumn(\n",
    "    'total', sum(pages[coln] for coln in pages.columns if coln not in ['userId', 'page_up_down_ratio'])\n",
    ")\n",
    "for coln in pages.columns:\n",
    "    if coln not in ['userId', 'total', 'page_up_down_ratio']:\n",
    "        new_col_name = coln[0:5]+'frac_'+coln[5:]\n",
    "        pages = pages.withColumn(new_col_name, pages[coln] / pages['total'])\n",
    "pages = pages.drop('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367b8226ba704011b8519cceb05e811d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the user's geographical division based on the first listed location state\n",
    "path = \"s3://aws-emr-resources-986775742469-us-east-2/region.csv\"\n",
    "region = spark.read.csv(path, header=True)\n",
    "\n",
    "func_locations = udf(lambda x: x.split(', ')[1].split('-')[0] if x!='' else 'none')\n",
    "func_location_names = udf(lambda x: \"location_\"+x.replace(\" \", \"_\").lower())\n",
    "locations = df.fillna('', subset=['location'])\\\n",
    "    .withColumn('location', func_locations(col('location')))\\\n",
    "    .select(['userId', 'location']).dropDuplicates(subset=['userId'])\n",
    "locations = locations.join(region, locations['location']==region['State Code'], how='left')\\\n",
    "    .select(['userId', col(\"Division\").alias(\"location\")]).fillna('none')\\\n",
    "    .withColumn('location', func_location_names('location'))\n",
    "locations = locations.groupBy('userId').pivot('location').agg(count('location')).fillna(0).drop('location_none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872efce9fe674150869d8286c9f69286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(userId=u'1000280', churn=1, level=0, gender=1, max(ts)=1542149985000, avg(registration)=1535470939000.0, time_since_regi=6679046.0, num_artists_dist=767, num_sessions=22, num_songs_dist=945, num_songs=1022, num_events=1317, tot_length=259349.89726000006, max_songs_per_artist=11, avg_songs_per_artist=1.332464146023468, std_songs_per_artist=1.018254818633842, std_time_per_session=10370.460836274826, avg_time_per_session=11694.363636363636, std_songs_per_session=41.453045465381415, avg_songs_per_session=46.45454545454545, user_agent_Macintosh=0.0, user_agent_Windows=1.0, user_agent_X11=0.0, user_agent_compatible=0.0, user_agent_iPad=0.0, user_agent_iPhone=0.0, user_agent_none=0.0, page_about=0, page_add_friend=14, page_add_to_playlist=25, page_error=3, page_help=8, page_home=44, page_login=0, page_logout=15, page_nextsong=1022, page_register=0, page_roll_advert=74, page_save_settings=1, page_settings=9, page_submit_downgrade=1, page_submit_registration=0, page_submit_upgrade=1, page_thumbs_down=33, page_thumbs_up=53, page_up_down_ratio=1.6012084592145015, page_frac_about=0.0, page_frac_add_friend=0.010744435917114352, page_frac_add_to_playlist=0.01918649270913277, page_frac_error=0.0023023791250959325, page_frac_help=0.0061396776669224865, page_frac_home=0.03376822716807368, page_frac_login=0.0, page_frac_logout=0.011511895625479662, page_frac_nextsong=0.7843438219493477, page_frac_register=0.0, page_frac_roll_advert=0.056792018419033, page_frac_save_settings=0.0007674597083653108, page_frac_settings=0.006907137375287797, page_frac_submit_downgrade=0.0007674597083653108, page_frac_submit_registration=0.0, page_frac_submit_upgrade=0.0007674597083653108, page_frac_thumbs_down=0.02532617037605526, page_frac_thumbs_up=0.04067536454336147, location_east_north_central=1, location_east_south_central=0, location_middle_atlantic=0, location_mountain=0, location_new_england=0, location_none=0, location_pacific=0, location_south_atlantic=0, location_west_north_central=0, location_west_south_central=0)"
     ]
    }
   ],
   "source": [
    "# # Join features together\n",
    "# dataset2 = churn.join(levels, ['userId'])\\\n",
    "#     .join(time_gender, ['userId'])\\\n",
    "#     .join(engagement, ['userId'])\\\n",
    "#     .join(per_artist, ['userId'])\\\n",
    "#     .join(per_session, ['userId'])\\\n",
    "#     .join(agents, ['userId'])\\\n",
    "#     .join(pages, ['userId'])\\\n",
    "#     .join(locations, ['userId'])\n",
    "\n",
    "# dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7755ec884d4d039d6c0e34a0c79381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Write data\n",
    "# path2 = \"s3://aws-emr-resources-986775742469-us-east-2/processed2.json\"\n",
    "# dataset2.write.format('json').save(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca52684ee47b4587a10117f0d9cb3c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(avg(registration)=1525261059000.0, avg_songs_per_artist=1.0863636363636364, avg_songs_per_session=59.75, avg_time_per_session=15133.25, churn=1, gender=0, level=1, location_east_north_central=0, location_east_south_central=0, location_middle_atlantic=0, location_mountain=0, location_new_england=0, location_none=0, location_pacific=0, location_south_atlantic=0, location_west_north_central=0, location_west_south_central=1, max(ts)=1540247149000, max_songs_per_artist=5, num_artists_dist=220, num_events=299, num_sessions=4, num_songs=239, num_songs_dist=233, page_about=0, page_add_friend=9, page_add_to_playlist=4, page_error=0, page_frac_about=0.0, page_frac_add_friend=0.03103448275862069, page_frac_add_to_playlist=0.013793103448275862, page_frac_error=0.0, page_frac_help=0.006896551724137931, page_frac_home=0.041379310344827586, page_frac_login=0.0, page_frac_logout=0.017241379310344827, page_frac_nextsong=0.8241379310344827, page_frac_register=0.0, page_frac_roll_advert=0.0, page_frac_save_settings=0.0034482758620689655, page_frac_settings=0.0034482758620689655, page_frac_submit_downgrade=0.0, page_frac_submit_registration=0.0, page_frac_submit_upgrade=0.0, page_frac_thumbs_down=0.013793103448275862, page_frac_thumbs_up=0.04482758620689655, page_help=2, page_home=12, page_login=0, page_logout=5, page_nextsong=239, page_register=0, page_roll_advert=0, page_save_settings=1, page_settings=1, page_submit_downgrade=0, page_submit_registration=0, page_submit_upgrade=0, page_thumbs_down=4, page_thumbs_up=13, page_up_down_ratio=3.1707317073170733, std_songs_per_artist=0.3784074469826433, std_songs_per_session=30.159299284521406, std_time_per_session=7773.058187311693, time_since_regi=14986090.0, tot_length=58037.12911999999, userId=u'1000353', user_agent_Macintosh=0.0, user_agent_Windows=1.0, user_agent_X11=0.0, user_agent_compatible=0.0, user_agent_iPad=0.0, user_agent_iPhone=0.0, user_agent_none=0.0)"
     ]
    }
   ],
   "source": [
    "# # Read in processed data\n",
    "# path2 = \"s3://aws-emr-resources-986775742469-us-east-2/processed2.json\"\n",
    "# dataset2 = spark.read.json(path2)\n",
    "# dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076b236475d34320b3c5acf4ad1a39e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# features_to_exclude = ['userId', 'churn', 'user_agent_none', 'location_none', 'page_frac_login',\n",
    "#                        'page_frac_register', 'page_frac_submit_registration', 'page_login', \n",
    "#                        'page_register', 'page_submit_registration', 'avg(registration)', 'max(ts)']\n",
    "# features_to_keep = [coln for coln in dataset2.columns if coln not in features_to_exclude]\n",
    "# feature_cols2 = dataset2.select(features_to_keep).columns\n",
    "# assembler = VectorAssembler(inputCols=feature_cols2, outputCol=\"features\")\n",
    "# dataset_vect = assembler.transform(dataset2.select(features_to_keep))\n",
    "# dataset_corr = Correlation.corr(dataset_vect, \"features\")\n",
    "# spearmanCorr = dataset_corr.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b871a57c6d425793ef6e28f51da69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Find correlated features that have absolute correlation >= 0.5\n",
    "# spearmanCorrList = [[float(ar) for ar in arr] for arr in spearmanCorr.toArray()]\n",
    "# corr_matrix = spark.createDataFrame(spearmanCorrList, schema=feature_cols2)\n",
    "# correlated_cols = []\n",
    "# for coln in corr_matrix.columns:\n",
    "#     correlated = corr_matrix.filter(Fabs(corr_matrix[coln])>=0.5).count()\n",
    "#     if correlated > 1:\n",
    "#         correlated_cols.append(coln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e9b1d40f4444b9b4085c0032fb07b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assembler_corr = VectorAssembler(inputCols=correlated_cols, outputCol=\"features\")\n",
    "# dataset_vect_corr = assembler_corr.transform(dataset2.select(correlated_cols))\n",
    "# dataset_corr_corr = Correlation.corr(dataset_vect_corr, \"features\")\n",
    "# spearmanCorr_corr = dataset_corr_corr.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e812bca6314bf9b409699bb04f8f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Find features to be removed, i.e. feature that has >0.8 correlation with any remaining feature\n",
    "# spearmanCorrList_corr = [[float(ar) for ar in arr] for arr in spearmanCorr_corr.toArray()]\n",
    "# corr = spark.createDataFrame(spearmanCorrList_corr, schema=correlated_cols)\n",
    "# corr = corr.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3c09a836bf4b4e9374779f7a5db5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated features that should be removed:\n",
      "\n",
      "['avg_songs_per_artist', 'avg_songs_per_session', 'avg_time_per_session', 'level', 'max_songs_per_artist', 'num_artists_dist', 'num_events', 'num_sessions', 'num_songs', 'num_songs_dist', 'page_about', 'page_add_friend', 'page_add_to_playlist', 'page_error', 'page_frac_home', 'page_frac_nextsong', 'page_frac_roll_advert', 'page_help', 'page_home', 'page_logout', 'page_nextsong', 'page_roll_advert', 'page_save_settings', 'page_settings', 'page_submit_downgrade', 'page_submit_upgrade', 'page_thumbs_down', 'page_thumbs_up', 'std_songs_per_artist', 'std_songs_per_session', 'std_time_per_session', 'tot_length', 'user_agent_Macintosh', 'user_agent_Windows']\n",
      "\n",
      "\n",
      "Features to keep:\n",
      "\n",
      "['avg(registration)', 'churn', 'gender', 'location_east_north_central', 'location_east_south_central', 'location_middle_atlantic', 'location_mountain', 'location_new_england', 'location_none', 'location_pacific', 'location_south_atlantic', 'location_west_north_central', 'location_west_south_central', 'max(ts)', 'page_frac_about', 'page_frac_add_friend', 'page_frac_add_to_playlist', 'page_frac_error', 'page_frac_help', 'page_frac_login', 'page_frac_logout', 'page_frac_register', 'page_frac_save_settings', 'page_frac_settings', 'page_frac_submit_downgrade', 'page_frac_submit_registration', 'page_frac_submit_upgrade', 'page_frac_thumbs_down', 'page_frac_thumbs_up', 'page_login', 'page_register', 'page_submit_registration', 'page_up_down_ratio', 'time_since_regi', 'userId', 'user_agent_X11', 'user_agent_compatible', 'user_agent_iPad', 'user_agent_iPhone', 'user_agent_none']"
     ]
    }
   ],
   "source": [
    "# cols_to_remove = []\n",
    "# counter = 0\n",
    "# for coln in corr.drop('id').columns:\n",
    "#     ind = corr.select('id').collect()[counter]['id']\n",
    "#     corr_ind = corr.select(coln).where(corr['id']>=ind)\n",
    "#     counter += 1\n",
    "#     if corr_ind.filter(Fabs(corr_ind[coln]) >= 0.8).count() > 0:\n",
    "#         cols_to_remove.append(coln)\n",
    "# print(\"Highly correlated features that should be removed:\\n\\n{}\\n\\n\".format(cols_to_remove))\n",
    "# cols_to_keep = [coln for coln in dataset2.columns if coln not in cols_to_remove]\n",
    "# print(\"Features to keep:\\n\\n{}\".format(cols_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537dc62bb0c04009ad47aa325046ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join features together\n",
    "dataset = churn.join(levels, ['userId'])\\\n",
    "    .join(time_gender, ['userId'])\\\n",
    "    .join(per_session, ['userId'])\\\n",
    "    .join(agents, ['userId'])\\\n",
    "    .join(pages, ['userId'])\\\n",
    "    .join(locations, ['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad26b8e34492447398145b228b9dff96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the highly correlated features\n",
    "cols_to_keep = [\n",
    "    'userId', 'churn', 'level', 'time_since_regi', 'gender', 'std_time_per_session', \n",
    "    'user_agent_Macintosh', 'user_agent_Windows', 'user_agent_X11', \n",
    "    'user_agent_compatible', 'user_agent_iPad', 'user_agent_iPhone', 'page_about', \n",
    "    'page_error', 'page_roll_advert', 'page_save_settings', 'page_submit_downgrade', \n",
    "    'page_submit_upgrade', 'page_thumbs_down', 'page_thumbs_up', 'page_frac_about', \n",
    "    'page_frac_add_friend', 'page_frac_add_to_playlist', 'page_frac_error', \n",
    "    'page_frac_help', 'page_frac_home', 'page_frac_logout', 'page_frac_nextsong', \n",
    "    'page_frac_roll_advert', 'page_frac_save_settings', 'page_frac_settings', \n",
    "    'page_frac_submit_downgrade', 'page_frac_submit_upgrade', 'page_frac_thumbs_down', \n",
    "    'page_frac_thumbs_up', 'location_east_north_central', 'location_east_south_central', \n",
    "    'location_middle_atlantic', 'location_mountain', 'location_new_england', \n",
    "    'location_pacific', 'location_south_atlantic', 'location_west_north_central', \n",
    "    'location_west_south_central', 'page_up_down_ratio'\n",
    "]\n",
    "dataset = dataset.select(cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4956796badac47128e8695db50866d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature transformation\n",
    "to_sqrt = ['std_time_per_session']\n",
    "to_log = [\n",
    "    'page_about', 'page_error', 'page_roll_advert', 'page_save_settings', \n",
    "    'page_thumbs_down', 'page_frac_about', 'page_frac_add_friend', \n",
    "    'page_frac_add_to_playlist', 'page_frac_error', 'page_frac_help', \n",
    "    'page_frac_home', 'page_frac_logout', 'page_frac_roll_advert', \n",
    "    'page_frac_save_settings', 'page_frac_settings', \n",
    "    'page_frac_submit_downgrade', 'page_frac_submit_upgrade', \n",
    "    'page_frac_thumbs_down', 'page_settings', 'page_thumbs_up',\n",
    "    'page_up_down_ratio'\n",
    "]\n",
    "col_names = [\n",
    "    coln for coln in dataset.columns if \n",
    "    ('churn' not in coln) and \n",
    "    ('level' not in coln) and\n",
    "    ('userId' not in coln) and\n",
    "    ('gender' not in coln) and\n",
    "    ('user_agent_' not in coln) and\n",
    "    ('location_' not in coln) and\n",
    "    ('_submit_' not in coln)\n",
    "]\n",
    "for col_name in col_names:\n",
    "    if col_name in to_sqrt:\n",
    "        dataset = dataset.withColumn(col_name, sqrt(dataset[col_name]+1))\n",
    "    elif col_name in to_log:\n",
    "        dataset = dataset.withColumn(col_name, log(dataset[col_name]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0d494daf3b4636b601d985137720f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 22278."
     ]
    }
   ],
   "source": [
    "print(\"Total number of rows in the dataset: {}.\".format(dataset.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3ee042b0ce445fb1f78ad526823142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['churn', 'gender', 'level', 'location_east_north_central', 'location_east_south_central', 'location_middle_atlantic', 'location_mountain', 'location_new_england', 'location_pacific', 'location_south_atlantic', 'location_west_north_central', 'location_west_south_central', 'page_about', 'page_error', 'page_frac_about', 'page_frac_add_friend', 'page_frac_add_to_playlist', 'page_frac_error', 'page_frac_help', 'page_frac_home', 'page_frac_logout', 'page_frac_nextsong', 'page_frac_roll_advert', 'page_frac_save_settings', 'page_frac_settings', 'page_frac_submit_downgrade', 'page_frac_submit_upgrade', 'page_frac_thumbs_down', 'page_frac_thumbs_up', 'page_roll_advert', 'page_save_settings', 'page_submit_downgrade', 'page_submit_upgrade', 'page_thumbs_down', 'page_thumbs_up', 'page_up_down_ratio', 'std_time_per_session', 'time_since_regi', 'userId', 'user_agent_Macintosh', 'user_agent_Windows', 'user_agent_X11', 'user_agent_compatible', 'user_agent_iPad', 'user_agent_iPhone']"
     ]
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57877c5518074e24bde5e31f8ff1038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column churn has 0 missing values.\n",
      "Column gender has 0 missing values.\n",
      "Column level has 0 missing values.\n",
      "Column location_east_north_central has 0 missing values.\n",
      "Column location_east_south_central has 0 missing values.\n",
      "Column location_middle_atlantic has 0 missing values.\n",
      "Column location_mountain has 0 missing values.\n",
      "Column location_new_england has 0 missing values.\n",
      "Column location_pacific has 0 missing values.\n",
      "Column location_south_atlantic has 0 missing values.\n",
      "Column location_west_north_central has 0 missing values.\n",
      "Column location_west_south_central has 0 missing values.\n",
      "Column page_about has 0 missing values.\n",
      "Column page_error has 0 missing values.\n",
      "Column page_frac_about has 0 missing values.\n",
      "Column page_frac_add_friend has 0 missing values.\n",
      "Column page_frac_add_to_playlist has 0 missing values.\n",
      "Column page_frac_error has 0 missing values.\n",
      "Column page_frac_help has 0 missing values.\n",
      "Column page_frac_home has 0 missing values.\n",
      "Column page_frac_logout has 0 missing values.\n",
      "Column page_frac_nextsong has 0 missing values.\n",
      "Column page_frac_roll_advert has 0 missing values.\n",
      "Column page_frac_save_settings has 0 missing values.\n",
      "Column page_frac_settings has 0 missing values.\n",
      "Column page_frac_submit_downgrade has 0 missing values.\n",
      "Column page_frac_submit_upgrade has 0 missing values.\n",
      "Column page_frac_thumbs_down has 0 missing values.\n",
      "Column page_frac_thumbs_up has 0 missing values.\n",
      "Column page_roll_advert has 0 missing values.\n",
      "Column page_save_settings has 0 missing values.\n",
      "Column page_submit_downgrade has 0 missing values.\n",
      "Column page_submit_upgrade has 0 missing values.\n",
      "Column page_thumbs_down has 0 missing values.\n",
      "Column page_thumbs_up has 0 missing values.\n",
      "Column page_up_down_ratio has 0 missing values.\n",
      "Column std_time_per_session has 0 missing values.\n",
      "Column time_since_regi has 0 missing values.\n",
      "Column userId has 0 missing values.\n",
      "Column user_agent_Macintosh has 0 missing values.\n",
      "Column user_agent_Windows has 0 missing values.\n",
      "Column user_agent_X11 has 0 missing values.\n",
      "Column user_agent_compatible has 0 missing values.\n",
      "Column user_agent_iPad has 0 missing values.\n",
      "Column user_agent_iPhone has 0 missing values."
     ]
    }
   ],
   "source": [
    "# Examine the number of missing values in each column\n",
    "for coln in dataset.columns:\n",
    "    missing_count = dataset.filter((isnan(dataset[coln])) | (dataset[coln].isNull()) | (dataset[coln] == \"\")).count()\n",
    "    print(\"Column {} has {} missing values.\".format(coln, missing_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20df5221a0e424289470dc78a749ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- churn: long (nullable = true)\n",
      " |-- gender: long (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- location_east_north_central: long (nullable = true)\n",
      " |-- location_east_south_central: long (nullable = true)\n",
      " |-- location_middle_atlantic: long (nullable = true)\n",
      " |-- location_mountain: long (nullable = true)\n",
      " |-- location_new_england: long (nullable = true)\n",
      " |-- location_pacific: long (nullable = true)\n",
      " |-- location_south_atlantic: long (nullable = true)\n",
      " |-- location_west_north_central: long (nullable = true)\n",
      " |-- location_west_south_central: long (nullable = true)\n",
      " |-- page_about: double (nullable = true)\n",
      " |-- page_error: double (nullable = true)\n",
      " |-- page_frac_about: double (nullable = true)\n",
      " |-- page_frac_add_friend: double (nullable = true)\n",
      " |-- page_frac_add_to_playlist: double (nullable = true)\n",
      " |-- page_frac_error: double (nullable = true)\n",
      " |-- page_frac_help: double (nullable = true)\n",
      " |-- page_frac_home: double (nullable = true)\n",
      " |-- page_frac_logout: double (nullable = true)\n",
      " |-- page_frac_nextsong: double (nullable = true)\n",
      " |-- page_frac_roll_advert: double (nullable = true)\n",
      " |-- page_frac_save_settings: double (nullable = true)\n",
      " |-- page_frac_settings: double (nullable = true)\n",
      " |-- page_frac_submit_downgrade: double (nullable = true)\n",
      " |-- page_frac_submit_upgrade: double (nullable = true)\n",
      " |-- page_frac_thumbs_down: double (nullable = true)\n",
      " |-- page_frac_thumbs_up: double (nullable = true)\n",
      " |-- page_roll_advert: double (nullable = true)\n",
      " |-- page_save_settings: double (nullable = true)\n",
      " |-- page_submit_downgrade: long (nullable = true)\n",
      " |-- page_submit_upgrade: long (nullable = true)\n",
      " |-- page_thumbs_down: double (nullable = true)\n",
      " |-- page_thumbs_up: double (nullable = true)\n",
      " |-- page_up_down_ratio: double (nullable = true)\n",
      " |-- std_time_per_session: double (nullable = true)\n",
      " |-- time_since_regi: double (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- user_agent_Macintosh: double (nullable = true)\n",
      " |-- user_agent_Windows: double (nullable = true)\n",
      " |-- user_agent_X11: double (nullable = true)\n",
      " |-- user_agent_compatible: double (nullable = true)\n",
      " |-- user_agent_iPad: double (nullable = true)\n",
      " |-- user_agent_iPhone: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ea33356dd3493f8c0948eb836b4f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"s3://aws-emr-resources-986775742469-us-east-2/processed.json\"\n",
    "# dataset.write.format('json').save(path)\n",
    "dataset.write.format('json').mode('overwrite').save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other syntax found online\n",
    "# df.write.parquet(\"s3a://bucket-name/shri/test.parquet\",mode=\"overwrite\")\n",
    "\n",
    "# dataset.write.format(\"org.apache.spark.sql.json\")\\\n",
    "#     .mode(SaveMode.Append).save(\"hdfs://localhost:9000/sampletext.txt\");\n",
    "\n",
    "# df.write.mode('append').json(yourtargetpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f7c47e6a5422da74c279f9f39e271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f78537f91649f888445abe3849e3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(churn=1, gender=0, level=1, location_east_north_central=0, location_east_south_central=0, location_middle_atlantic=0, location_mountain=0, location_new_england=0, location_pacific=0, location_south_atlantic=0, location_west_north_central=0, location_west_south_central=1, page_about=0.0, page_error=0.0, page_frac_about=0.0, page_frac_add_friend=0.030562650410166668, page_frac_add_to_playlist=0.013698844358161927, page_frac_error=0.0, page_frac_help=0.0068728792877620504, page_frac_home=0.04054609439435001, page_frac_logout=0.01709443335930004, page_frac_nextsong=0.8241379310344827, page_frac_roll_advert=0.0, page_frac_save_settings=0.0034423441909726986, page_frac_settings=0.0034423441909726986, page_frac_submit_downgrade=0.0, page_frac_submit_upgrade=0.0, page_frac_thumbs_down=0.013698844358161927, page_frac_thumbs_up=0.04482758620689655, page_roll_advert=0.0, page_save_settings=0.6931471805599453, page_submit_downgrade=0, page_submit_upgrade=0, page_thumbs_down=1.6094379124341003, page_thumbs_up=2.6390573296152584, page_up_down_ratio=1.428091489798352, std_time_per_session=88.17061975120563, time_since_regi=14986090.0, userId=u'1000353', user_agent_Macintosh=0.0, user_agent_Windows=1.0, user_agent_X11=0.0, user_agent_compatible=0.0, user_agent_iPad=0.0, user_agent_iPhone=0.0)"
     ]
    }
   ],
   "source": [
    "# Read in processed data\n",
    "path = \"s3://aws-emr-resources-986775742469-us-east-2/processed.json\"\n",
    "dataset = spark.read.json(path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea0d6aff8b5493db4c2c4cc40cf2edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename churn column into label\n",
    "dataset = dataset.withColumn('label', dataset['churn'].cast('float')).drop('churn') #important to have float type\n",
    "\n",
    "# Feature columns to be converted into vector\n",
    "feature_cols = dataset.drop('label').drop('userId').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfcf317a7ba4a52b244289e5b7ec48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train-test split\n",
    "train, test = dataset.drop('userId').randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff3397a356d4007a9a73c44e7760834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def buildCV(classifier, paramGrid):\n",
    "    '''\n",
    "    Build a cross validation pipeline\n",
    "    \n",
    "    INPUT\n",
    "    classifier: untrained machine learning classifier\n",
    "    paramGrid: a grid of parameters to search over\n",
    "    \n",
    "    OUTPUT\n",
    "    crossval: cross validator\n",
    "    '''\n",
    "    # Configure an ML pipeline\n",
    "    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"rawFeatures\")\n",
    "    scaler = MaxAbsScaler(inputCol=\"rawFeatures\", outputCol=\"scaledFeatures\")\n",
    "#     scaler = MinMaxScaler(inputCol=\"rawFeatures\", outputCol=\"scaledFeatures\")\n",
    "#     scaler = StandardScaler(inputCol=\"rawFeatures\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, classifier])\n",
    "\n",
    "    # Cross validation\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=MulticlassClassificationEvaluator(metricName='f1'),\n",
    "        numFolds=3\n",
    "    )\n",
    "    return crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863f72b8140c4d98b3c12e990dd85ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def trainModel(classifier, train, paramGrid):\n",
    "    '''\n",
    "    Train the machine learning model\n",
    "    \n",
    "    INPUT\n",
    "    classifier: untrained machine learning classifier\n",
    "    paramGrid: a grid of parameters to search over\n",
    "    train (Spark dataframe): training dataset\n",
    "    \n",
    "    OUTPUT\n",
    "    model: trained machine learning model\n",
    "    training_time (float): training time\n",
    "    '''\n",
    "    crossval = buildCV(classifier, paramGrid)\n",
    "    start = time()\n",
    "    model = crossval.fit(train)\n",
    "    end = time()\n",
    "    training_time = end - start\n",
    "    return model, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58372ab056bf48ee98fa74fa1e520d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluateModel(model, data, prob=False):\n",
    "    '''\n",
    "    Evaluate model performance\n",
    "    \n",
    "    INPUT\n",
    "    model: trained machine learning model\n",
    "    data (Spark dataframe): either training set or testing set\n",
    "    \n",
    "    OUTPUT\n",
    "    evalMetrics (dict): disctionary of evaluation metrics\n",
    "    '''\n",
    "    # Make prediction\n",
    "    start = time()\n",
    "    pred = model.transform(data)\n",
    "    if prob:\n",
    "        evaluator = MulticlassClassificationEvaluator(predictionCol=\"probability\", labelCol=\"label\")\n",
    "    else:\n",
    "        evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "    end = time()\n",
    "    prediction_time = end - start\n",
    "    \n",
    "    # Calculate metrics\n",
    "    evalMetrics = {}\n",
    "    evalMetrics[\"precision\"] = evaluator.evaluate(pred, {evaluator.metricName: \"weightedPrecision\"})\n",
    "    evalMetrics[\"recall\"] = evaluator.evaluate(pred, {evaluator.metricName: \"weightedRecall\"})\n",
    "    evalMetrics[\"f1\"] = evaluator.evaluate(pred, {evaluator.metricName: \"f1\"})\n",
    "    evalMetrics[\"accuracy\"] = evaluator.evaluate(pred, {evaluator.metricName: \"accuracy\"})\n",
    "    evalMetrics['confusion_matrix'] = pred.groupby(\"label\").pivot(\"prediction\").count()\n",
    "    evalMetrics['prediction_time'] = prediction_time\n",
    "    \n",
    "    return evalMetrics\n",
    "\n",
    "def evaluateTrainTest(model, train, test, training_time):\n",
    "    '''\n",
    "    Evaluate model performance on both training and testing sets\n",
    "    \n",
    "    INPUT\n",
    "    model: trained machine learning model\n",
    "    train: training set\n",
    "    test: testing set\n",
    "    training_time (float): training time\n",
    "    \n",
    "    OUTPUT\n",
    "    evalMetrics (dict): disctionary of evaluation metrics, \n",
    "        compiled from training, testing metrics\n",
    "    summary (Spark dataframe): table of evaluation metrics\n",
    "    '''\n",
    "    # Evaluate model performance\n",
    "    evalMetricsTraining = evaluateModel(model, train)\n",
    "    evalMetricsTesting = evaluateModel(model, test)\n",
    "\n",
    "    # Compile metrics\n",
    "    evalMetrics = {}\n",
    "    evalMetrics['train_time'] = training_time\n",
    "    evalMetrics['f1_train'] = evalMetricsTraining['f1']\n",
    "    evalMetrics['acc_train'] = evalMetricsTraining['accuracy']\n",
    "    evalMetrics['f1_test'] = evalMetricsTesting['f1']\n",
    "    evalMetrics['acc_test'] = evalMetricsTesting['accuracy']\n",
    "    evalMetrics['pred_time'] = evalMetricsTraining['prediction_time'] \\\n",
    "        + evalMetricsTesting['prediction_time']\n",
    "\n",
    "    # Summarize metrics into a Spark dataframe\n",
    "    metrics_to_display = {\n",
    "        k:round(v, 4) for k,v in evalMetrics.items() if ('confusion_matrix' not in k)\n",
    "    }\n",
    "    summary = spark.createDataFrame([list(metrics_to_display.values())], list(metrics_to_display.keys()))\n",
    "    \n",
    "    return evalMetrics, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09bf31591a84e38b33b9cdcf02e117a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lump all steps together\n",
    "def trainAndEval(classifier, train, test, paramGrid):\n",
    "    '''\n",
    "    Train and evaluate model performance on both training and testing sets\n",
    "    \n",
    "    INPUT\n",
    "    classifier: untrained machine learning classifier\n",
    "    train: training set\n",
    "    test: testing set\n",
    "    paramGrid: a grid of parameters to search over\n",
    "    \n",
    "    OUTPUT\n",
    "    evalMetrics (dict): disctionary of evaluation metrics, \n",
    "        compiled from training, testing metrics\n",
    "    summary (Spark dataframe): table of evaluation metrics\n",
    "    model: trained machine learning model\n",
    "    '''\n",
    "    # Train the model\n",
    "    model, training_time = trainModel(classifier, train, paramGrid)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    evalMetricsTraining = evaluateModel(model, train)\n",
    "    evalMetricsTesting = evaluateModel(model, test)\n",
    "\n",
    "    # Compile metrics\n",
    "    evalMetrics = {}\n",
    "    evalMetrics['train_time'] = training_time\n",
    "    evalMetrics['f1_train'] = evalMetricsTraining['f1']\n",
    "    evalMetrics['acc_train'] = evalMetricsTraining['accuracy']\n",
    "    evalMetrics['f1_test'] = evalMetricsTesting['f1']\n",
    "    evalMetrics['acc_test'] = evalMetricsTesting['accuracy']\n",
    "    evalMetrics['pred_time'] = evalMetricsTraining['prediction_time'] \\\n",
    "        + evalMetricsTesting['prediction_time']\n",
    "\n",
    "    # Summarize metrics into a Spark dataframe\n",
    "    metrics_to_display = {\n",
    "        k:round(v, 4) for k,v in evalMetrics.items() if ('confusion_matrix' not in k)\n",
    "    }\n",
    "    summary = spark.createDataFrame([list(metrics_to_display.values())], list(metrics_to_display.keys()))\n",
    "    \n",
    "    return evalMetrics, summary, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f63f8cf421646d5b9093d8610e1e88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check later\n",
    "# spark.executor.heartbeatInterval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7e4ab98360400696b5cd03779e855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:\n",
      "+-------+---------+--------+--------+\n",
      "|f1_test|acc_train|acc_test|f1_train|\n",
      "+-------+---------+--------+--------+\n",
      "| 0.8229|   0.8515|  0.8387|  0.8362|\n",
      "+-------+---------+--------+--------+"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "classifier = GBTClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "# Construct a grid of parameters to search over\n",
    "# paramGrid = ParamGridBuilder()\\\n",
    "#     .addGrid(classifier.maxIter, [20, 50, 100, 200])\n",
    "#     .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "#     .addGrid(classifier.fitIntercept, [False, True])\\\n",
    "#     .addGrid(classifier.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "#     .build()\n",
    "\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(classifier.maxDepth,[5, 10]) \\\n",
    "#     .addGrid(classifier.numTrees, [20, 50, 100, 200]) \\\n",
    "#     .addGrid(classifier.minInstancesPerNode, [1, 5, 10, 50]) \\\n",
    "#     .addGrid(classifier.subsamplingRate, [0.4, 0.7, 1.0]) \\\n",
    "#     .build()\n",
    "\n",
    "# paramGrid = ParamGridBuilder()\\\n",
    "#     .addGrid(classifier.featureSubsetStrategy, ['auto', 'all', 'onethird', 'sqrt'])\\\n",
    "#     .addGrid(classifier.maxDepth,[5, 10, 20])\\\n",
    "#     .addGrid(classifier.maxIter, [20, 50, 100])\\\n",
    "#     .addGrid(classifier.minInstancesPerNode, [1, 5, 10, 50])\\\n",
    "#     .addGrid(classifier.subsamplingRate, [0.4, 0.7, 1.0])\\\n",
    "#     .build()\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.maxDepth,[5, 10])\\\n",
    "    .addGrid(classifier.maxIter, [20, 50])\\\n",
    "    .build()\n",
    "\n",
    "# Train the model\n",
    "model, training_time = trainModel(classifier, train, paramGrid)\n",
    "\n",
    "# Evaluate model performance\n",
    "evalMetrics, summary = evaluateTrainTest(model, train, test, training_time)\n",
    "\n",
    "# Show metrics\n",
    "print(\"Best model:\")\n",
    "summary.drop('train_time').drop('pred_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b3b0ceabe94900b27e3e1434aa2a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'level', 'location_east_north_central', 'location_east_south_central', 'location_middle_atlantic', 'location_mountain', 'location_new_england', 'location_pacific', 'location_south_atlantic', 'location_west_north_central', 'location_west_south_central', 'page_about', 'page_error', 'page_frac_about', 'page_frac_add_friend', 'page_frac_add_to_playlist', 'page_frac_error', 'page_frac_help', 'page_frac_home', 'page_frac_logout', 'page_frac_nextsong', 'page_frac_roll_advert', 'page_frac_save_settings', 'page_frac_settings', 'page_frac_submit_downgrade', 'page_frac_submit_upgrade', 'page_frac_thumbs_down', 'page_frac_thumbs_up', 'page_roll_advert', 'page_save_settings', 'page_submit_upgrade', 'page_thumbs_down', 'page_thumbs_up', 'page_up_down_ratio', 'std_time_per_session', 'time_since_regi', 'user_agent_Macintosh', 'user_agent_Windows', 'user_agent_X11', 'user_agent_compatible', 'user_agent_iPad']\n",
      "()\n",
      "[0.00011934404163344246, 0.05998992893742344, 0.00826396386802028, 0.00132816504518676, 0.003551985347536029, 0.0043097419472642225, 0.0010843766604710617, 0.00389598561282858, 1.3811217349589099e-05, 0.0010908283100556076, 0.0031641238693605324, 0.008261258669485466, 0.005046679792084945, 0.021131340399483445, 0.022175087512200427, 0.012157034186842046, 0.007057782594066586, 0.013796412932499225, 0.017201910440686925, 0.035245468449417734, 0.046313306598371025, 0.09301677879058637, 0.004044404972463019, 0.036260642854789506, 0.03143272802863946, 0.03264476772127877, 0.03317911992112093, 0.08729074517283748, 0.07088931089402672, 0.003055500312424752, 0.006169492560247691, 0.034911128101213273, 0.02984439620231532, 0.05113416745399484, 0.04882327310246906, 0.14934062827947905, 0.0012374023104875361, 0.005632780031748963, 0.0016246803242076936, 0.0030024081253874676, 0.0012671084080145252]"
     ]
    }
   ],
   "source": [
    "# Best model and parameters\n",
    "bestModel = model.bestModel\n",
    "bestCLModel = bestModel.stages[2]\n",
    "bestParams = bestCLModel.extractParamMap()\n",
    "\n",
    "# Feature importance\n",
    "feature_ind = bestCLModel.featureImportances.indices.tolist()\n",
    "feature_name = [feature_cols[ind] for ind in feature_ind]\n",
    "feature_coef = bestCLModel.featureImportances.values.tolist()\n",
    "print(feature_name)\n",
    "print()\n",
    "print(feature_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
